# pytest: disable
common:
  run_label: train
  log_freq: 500
  auto_resume: true
  mixed_precision: true
  tensorboard_logging: false
  accum_freq: 2
dataset:
  root_train: /mnt/audio_datasets/google_speech_recognition_v2
  root_val: /mnt/audio_datasets/google_speech_recognition_v2
  name: speech_commands_v2
  category: audio_classification
  train_batch_size0: 48
  val_batch_size0: 48
  eval_batch_size0: 48
  workers: 10
  persistent_workers: false
  pin_memory: true
  collate_fn_name_train: byteformer_audio_collate_fn
  collate_fn_name_val: byteformer_audio_collate_fn
  collate_fn_name_test: byteformer_audio_collate_fn
  speech_commands_v2:
    mixup: true
audio_augmentation:
  noise:
    enable: true
    levels:
    - -50
    refresh_freq: 100
  roll:
    enable: true
    window: 0.1
  torchaudio_save:
    enable: true
    encoding_dtype: uint8
    format: wav
sampler:
  name: batch_sampler
loss:
  category: classification
  classification:
    name: cross_entropy
    cross_entropy:
      label_smoothing: 0.1
optim:
  name: adamw
  weight_decay: 0.05
  no_decay_bn_filter_bias: true
  adamw:
    beta1: 0.9
    beta2: 0.999
scheduler:
  name: cosine
  is_iteration_based: false
  max_epochs: 300
  warmup_iterations: 500
  warmup_init_lr: 1.0e-06
  cosine:
    max_lr: 0.001
    min_lr: 2.0e-05
model:
  audio_classification:
    name: byteformer
  classification:
    name: byteformer
    byteformer:
      mode: tiny
      max_num_tokens: 50000
      conv_kernel_size: 16
      window_sizes:
      - 128
    n_classes: 12
  activation:
    name: gelu
  layer:
    global_pool: mean
    conv_init: kaiming_uniform
    linear_init: trunc_normal
    linear_init_std_dev: 0.02
ema:
  enable: true
  momentum: 0.0001
stats:
  val:
  - loss
  - top1
  - top5
  train:
  - loss
  checkpoint_metric: top1
  checkpoint_metric_max: true
